# FedITS-Tool Full Project Dump
- Root: `/home/veins/fedits-tool`
- Files: **24**
- Generated at: `2026-02-09 13:50:41`

---

## Index

- [configs/base.yaml](#configsbaseyaml)
- [configs/scenarios/urban_1km_100veh_r300.yaml](#configsscenariosurban1km100vehr300yaml)
- [docker/docker-compose.yml](#dockerdockercomposeyml)
- [docker/docker-compose_original.yml](#dockerdockercomposeoriginalyml)
- [docker/Dockerfile.client](#dockerdockerfileclient)
- [docker/Dockerfile.server](#dockerdockerfileserver)
- [fl/__init__.py](#flinitpy)
- [fl/client copy.py](#flclientcopypy)
- [fl/client.py](#flclientpy)
- [fl/server.py](#flserverpy)
- [fl/server_original_替换版本.py](#flserveroriginal替换版本py)
- [Makefile](#makefile)
- [orchestrator/__init__.py](#orchestratorinitpy)
- [orchestrator/flwr_adapter.py](#orchestratorflwradapterpy)
- [orchestrator/orch_core.py](#orchestratororchcorepy)
- [orchestrator/orch_http_client.py](#orchestratororchhttpclientpy)
- [orchestrator/orch_service.py](#orchestratororchservicepy)
- [orchestrator/orchestrator.py](#orchestratororchestratorpy)
- [orchestrator/veins_client.py](#orchestratorveinsclientpy)
- [README.md](#readmemd)
- [requirements.txt](#requirementstxt)
- [scripts/collect_last_run.sh](#scriptscollectlastrunsh)
- [scripts/run_mock.sh](#scriptsrunmocksh)
- [scripts/run_rpc.sh](#scriptsrunrpcsh)

---

## configs/base.yaml
<a id="configsbaseyaml"></a>

- Path: `/home/veins/fedits-tool/configs/base.yaml`
```yaml
sim:
  map_size_m: 1000
  num_vehicles: 100

rsu:
  x_m: 500
  y_m: 500
  radius_m: 300

fl:
  rounds: 10
  clients_per_round: 10
  round_deadline_s: 25
  model_down_bytes: 2000000
  model_up_bytes: 2000000

carbon:
  ci_g_per_kwh: 200

radio_power:
  p_rx_w: 1.0
  p_tx_w: 1.5
```

---

## configs/scenarios/urban_1km_100veh_r300.yaml
<a id="configsscenariosurban1km100vehr300yaml"></a>

- Path: `/home/veins/fedits-tool/configs/scenarios/urban_1km_100veh_r300.yaml`
```yaml
inherit: ../base.yaml

sim:
  num_vehicles: 100

rsu:
  radius_m: 300

fl:
  clients_per_round: 10
  round_deadline_s: 25
```

---

## docker/docker-compose.yml
<a id="dockerdockercomposeyml"></a>

- Path: `/home/veins/fedits-tool/docker/docker-compose.yml`
```yaml
version: "3.9"

services:
  orchestrator:
    build:
      context: ..
      dockerfile: docker/Dockerfile.server   # 复用镜像
    container_name: orchestrator
    command: ["python", "-u", "orchestrator/orch_service.py"]
    ports:
      - "7070:7070"
    environment:
      OUT_DIR: outputs

      # Veins side
      VEINS_MODE: rpc           # mock | rpc
      VEINS_HOST: 172.17.0.1    # Linux host gateway (Veins runs on host)
      VEINS_PORT: 9999

      # scenario params (must match your Veins/SUMO)
      MAP_SIZE_M: 1000
      NUM_VEH: 100
      RSU_X_M: 500
      RSU_Y_M: 500
      RSU_R_M: 300

      # FL params
      ROUNDS: 10
      M: 10
      DEADLINE_S: 25
      MODEL_DOWN_BYTES: 2000000
      MODEL_UP_BYTES: 2000000

      # carbon/radio
      CI_G_PER_KWH: 200
      P_RX_W: 1.0
      P_TX_W: 1.5

  fl_server:
    build:
      context: ..
      dockerfile: docker/Dockerfile.server
    container_name: fl_server
    depends_on: [orchestrator]
    ports:
      - "8080:8080"
    environment:
      SERVER_ADDR: 0.0.0.0:8080
      ROUNDS: 10
      ORCH_URL: http://orchestrator:7070

  fl_client:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.10
```

---

## docker/docker-compose_original.yml
<a id="dockerdockercomposeoriginalyml"></a>

- Path: `/home/veins/fedits-tool/docker/docker-compose_original.yml`
```yaml
version: "3.9"

services:
  fl_server:
    build:
      context: ..
      dockerfile: docker/Dockerfile.server
    container_name: fl_server
    ports:
      - "8080:8080"
    environment:
      # output
      OUT_DIR: outputs

      # Veins mode: mock first, later change to rpc
      VEINS_MODE: mock
      VEINS_HOST: 127.0.0.1
      VEINS_PORT: 9999

      # scenario
      MAP_SIZE_M: 1000
      NUM_VEH: 100
      RSU_X_M: 500
      RSU_Y_M: 500
      RSU_R_M: 300

      # FL
      SEED: 42
      ROUNDS: 5
      M: 10
      DEADLINE_S: 25

      # model sizes (bytes)
      MODEL_DOWN_BYTES: 2000000
      MODEL_UP_BYTES: 2000000

      # carbon + comm power model
      CI_G_PER_KWH: 200
      P_RX_W: 1.0
      P_TX_W: 1.5

      # bind
      SERVER_ADDR: 0.0.0.0:8080
    volumes:
      - ../outputs:/app/outputs

  fl_client_01:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_01
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client01
      # compute mock knobs
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.1

  fl_client_02:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_02
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client02
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.2

  fl_client_03:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_03
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client03
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.0

  fl_client_04:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_04
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client04
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.05

  fl_client_05:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_05
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client05
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.15

  fl_client_06:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_06
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client06
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.25

  fl_client_07:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_07
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client07
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.05

  fl_client_08:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_08
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client08
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.12

  fl_client_09:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_09
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client09
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.0

  fl_client_10:
    build:
      context: ..
      dockerfile: docker/Dockerfile.client
    container_name: fl_client_10
    depends_on: [fl_server]
    environment:
      SERVER_ADDR: fl_server:8080
      CLIENT_ID: client10
      P_COMP_W: 18
      CI_G_PER_KWH: 200
      SLEEP_SCALE: 0.18
```

---

## docker/Dockerfile.client
<a id="dockerdockerfileclient"></a>

- Path: `/home/veins/fedits-tool/docker/Dockerfile.client`
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . /app

RUN pip install --no-cache-dir -r requirements.txt

CMD ["python", "-u", "fl/client.py"]
```

---

## docker/Dockerfile.server
<a id="dockerdockerfileserver"></a>

- Path: `/home/veins/fedits-tool/docker/Dockerfile.server`
```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . /app

RUN pip install --no-cache-dir -r requirements.txt

EXPOSE 8080
CMD ["python", "-u", "fl/server.py"]
```

---

## fl/__init__.py
<a id="flinitpy"></a>

- Path: `/home/veins/fedits-tool/fl/__init__.py`
```python

```

---

## fl/client copy.py
<a id="flclientcopypy"></a>

- Path: `/home/veins/fedits-tool/fl/client copy.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import random
from typing import Dict, List, Tuple

import numpy as np
import flwr as fl
from flwr.common import Parameters, ndarrays_to_parameters, parameters_to_ndarrays


def env_str(name: str, default: str) -> str:
    return str(os.getenv(name, default))

def env_float(name: str, default: float) -> float:
    try:
        return float(os.getenv(name, default))
    except Exception:
        return default

def env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except Exception:
        return default

def joule_to_kwh(j: float) -> float:
    return j / 3_600_000.0


class SyntheticClient(fl.client.NumPyClient):
    """
    Minimal client:
    - model is a vector of length D
    - local training: do a few gradient steps on synthetic linear regression
    - reports t_train_s, e_comp_j, co2_comp_g in metrics
    """

    def __init__(self, cid: str, dim: int = 10) -> None:
        self.cid = cid
        self.dim = dim

        self.p_comp_w = env_float("P_COMP_W", 18.0)          # mock compute power
        self.ci_g_per_kwh = env_float("CI_G_PER_KWH", 200.0) # can be overwritten by server later

        # heterogeneity knob: extra sleep to emulate slow devices
        self.sleep_scale = env_float("SLEEP_SCALE", 0.0)     # e.g., 0.5 makes slower

        # fixed local dataset seed by cid
        self.rnd = random.Random(hash(cid) & 0xFFFFFFFF)

        # synthetic dataset
        self.n = env_int("N_SAMPLES", 200)
        self.X = self._randn(self.n, self.dim)
        # per-client true weight
        w_true = np.array([self.rnd.uniform(-1, 1) for _ in range(self.dim)], dtype=np.float32)
        noise = 0.1 * self._randn(self.n, 1).reshape(-1)
        self.y = (self.X @ w_true) + noise

    def _randn(self, n: int, d: int) -> np.ndarray:
        # deterministic numpy RNG per client
        rng = np.random.RandomState(hash((self.cid, n, d)) & 0xFFFFFFFF)
        return rng.randn(n, d).astype(np.float32)

    def get_parameters(self, config: Dict) -> List[np.ndarray]:
        # initial params = zeros
        return [np.zeros((self.dim,), dtype=np.float32)]

    def fit(self, parameters: List[np.ndarray], config: Dict) -> Tuple[List[np.ndarray], int, Dict]:
        w = parameters[0].astype(np.float32).copy()

        # local training hyperparams
        lr = float(config.get("lr", env_float("LR", 0.05)))
        steps = int(config.get("steps", env_int("STEPS", 20)))
        veh_id = str(config.get("veh_id", ""))
        server_round = int(config.get("server_round", 0))

        t0 = time.time()

        # simple SGD on MSE: grad = X^T (Xw - y)/n
        for _ in range(steps):
            pred = self.X @ w
            grad = (self.X.T @ (pred - self.y)) / float(self.n)
            w -= lr * grad.astype(np.float32)

        # optional sleep to emulate slower compute
        if self.sleep_scale > 0:
            time.sleep(self.sleep_scale * self.rnd.uniform(0.0, 1.0))

        t1 = time.time()
        t_train_s = float(t1 - t0)

        # compute energy/carbon (mock; later you replace with real measurement)
        e_comp_j = self.p_comp_w * t_train_s
        co2_comp_g = joule_to_kwh(e_comp_j) * self.ci_g_per_kwh

        metrics = {
            "cid": self.cid,
            "veh_id": veh_id,
            "t_train_s": t_train_s,
            "e_comp_j": e_comp_j,
            "co2_comp_g": co2_comp_g,
            "server_round": server_round,
        }

        return [w], self.n, metrics

    def evaluate(self, parameters: List[np.ndarray], config: Dict) -> Tuple[float, int, Dict]:
        # MVP: no evaluation
        return 0.0, self.n, {}


def main() -> None:
    server_addr = env_str("SERVER_ADDR", "fl_server:8080")
    cid = env_str("CLIENT_ID", "clientX")

    client = SyntheticClient(cid=cid, dim=10)

    # Robust connect loop (server may not be ready)
    while True:
        try:
            fl.client.start_numpy_client(server_address=server_addr, client=client)
            break
        except Exception as e:
            print(f"[{cid}] connect failed ({e}), retry in 2s...")
            time.sleep(2)


if __name__ == "__main__":
    main()
```

---

## fl/client.py
<a id="flclientpy"></a>

- Path: `/home/veins/fedits-tool/fl/client.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import random
import re
from typing import Dict, List, Tuple

import numpy as np
import flwr as fl


def env_str(name: str, default: str) -> str:
    return str(os.getenv(name, default))

def env_float(name: str, default: float) -> float:
    try:
        return float(os.getenv(name, default))
    except Exception:
        return default

def env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except Exception:
        return default

def joule_to_kwh(j: float) -> float:
    return j / 3_600_000.0

def derive_client_id() -> str:
    # 1) explicit env wins
    cid = os.getenv("CLIENT_ID", "").strip()
    if cid:
        return cid

    # 2) docker scale hostname like: fl_client-1 / fl_client_1 / <hash>
    hn = os.getenv("HOSTNAME", "clientX")
    m = re.search(r"(\d+)$", hn)
    if m:
        i = int(m.group(1))
        n = max(i - 1, 0)  # 0-based
        return f"client{n:02d}" if n <= 99 else f"client{n:03d}"
    return "clientX"


class SyntheticClient(fl.client.NumPyClient):
    """
    Minimal compute-plane client:
    - model: vector length D
    - local training: SGD on synthetic regression
    - metrics: t_train_s, e_comp_j, co2_comp_g, veh_id (for control-plane use)
    """

    def __init__(self, cid: str, dim: int = 10) -> None:
        self.cid = cid
        self.dim = dim

        # compute/energy params (replace later with real measurement)
        self.p_comp_w = env_float("P_COMP_W", 18.0)
        self.ci_g_per_kwh = env_float("CI_G_PER_KWH", 200.0)

        # heterogeneity knob
        self.sleep_scale = env_float("SLEEP_SCALE", 0.0)

        self.rnd = random.Random(hash(cid) & 0xFFFFFFFF)

        # synthetic dataset
        self.n = env_int("N_SAMPLES", 200)
        self.X = self._randn(self.n, self.dim)
        w_true = np.array([self.rnd.uniform(-1, 1) for _ in range(self.dim)], dtype=np.float32)
        noise = 0.1 * self._randn(self.n, 1).reshape(-1)
        self.y = (self.X @ w_true) + noise

    def _randn(self, n: int, d: int) -> np.ndarray:
        rng = np.random.RandomState(hash((self.cid, n, d)) & 0xFFFFFFFF)
        return rng.randn(n, d).astype(np.float32)

    def get_parameters(self, config: Dict) -> List[np.ndarray]:
        return [np.zeros((self.dim,), dtype=np.float32)]

    def fit(self, parameters: List[np.ndarray], config: Dict) -> Tuple[List[np.ndarray], int, Dict]:
        w = parameters[0].astype(np.float32).copy()

        lr = float(config.get("lr", env_float("LR", 0.05)))
        steps = int(config.get("steps", env_int("STEPS", 20)))

        # IMPORTANT: veh_id comes from Orchestrator -> server -> client config
        veh_id = str(config.get("veh_id", ""))
        server_round = int(config.get("server_round", 0))

        # Orchestrator may pass CI; if present override
        if "ci_g_per_kwh" in config:
            try:
                self.ci_g_per_kwh = float(config["ci_g_per_kwh"])
            except Exception:
                pass

        t0 = time.time()

        for _ in range(steps):
            pred = self.X @ w
            grad = (self.X.T @ (pred - self.y)) / float(self.n)
            w -= lr * grad.astype(np.float32)

        if self.sleep_scale > 0:
            time.sleep(self.sleep_scale * self.rnd.uniform(0.0, 1.0))

        t1 = time.time()
        t_train_s = float(t1 - t0)

        e_comp_j = self.p_comp_w * t_train_s
        co2_comp_g = joule_to_kwh(e_comp_j) * self.ci_g_per_kwh

        metrics = {
            "veh_id": veh_id,
            "t_train_s": t_train_s,
            "e_comp_j": e_comp_j,
            "co2_comp_g": co2_comp_g,
            "server_round": server_round,
        }

        return [w], self.n, metrics

    def evaluate(self, parameters: List[np.ndarray], config: Dict) -> Tuple[float, int, Dict]:
        return 0.0, self.n, {}


def main() -> None:
    server_addr = env_str("SERVER_ADDR", "fl_server:8080")
    cid = derive_client_id()

    client = SyntheticClient(cid=cid, dim=10)

    while True:
        try:
            fl.client.start_numpy_client(server_address=server_addr, client=client)
            break
        except Exception as e:
            print(f"[{cid}] connect failed ({e}), retry in 2s...")
            time.sleep(2)


if __name__ == "__main__":
    main()
```

---

## fl/server.py
<a id="flserverpy"></a>

- Path: `/home/veins/fedits-tool/fl/server.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import urllib.request
from typing import Dict, List, Tuple, Optional, Any

import numpy as np
import flwr as fl
from flwr.common import (
    FitIns,
    FitRes,
    Parameters,
    ndarrays_to_parameters,
    parameters_to_ndarrays,
)
from flwr.server.client_manager import ClientManager


# -------------------------
# Helpers
# -------------------------

def env_str(name: str, default: str) -> str:
    return str(os.getenv(name, default))

def env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except Exception:
        return default

def vec_norm(x: np.ndarray) -> float:
    return float(np.sqrt(np.sum(x * x)))

class OrchestratorHttpClient:
    """Minimal HTTP client for Orchestrator control-plane service."""
    def __init__(self, base_url: str, timeout_s: float = 60.0) -> None:
        self.base_url = base_url.rstrip("/")
        self.timeout_s = float(timeout_s)

    def post(self, path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        url = self.base_url + path
        data = json.dumps(payload).encode("utf-8")
        req = urllib.request.Request(url, data=data, method="POST")
        req.add_header("Content-Type", "application/json")
        with urllib.request.urlopen(req, timeout=self.timeout_s) as resp:
            text = resp.read().decode("utf-8").strip()
            return json.loads(text) if text else {}

    def get(self, path: str) -> Dict[str, Any]:
        url = self.base_url + path
        with urllib.request.urlopen(url, timeout=self.timeout_s) as resp:
            text = resp.read().decode("utf-8").strip()
            return json.loads(text) if text else {}


# -------------------------
# Proxy Strategy (strict separation)
# -------------------------

class ProxyOrchestratedFedAvg(fl.server.strategy.Strategy):
    """
    STRICT separation:
      - Orchestrator (control plane): selection, Veins down/up simulation, commit/drop, CSV logs, t_sim advance
      - Flower server (data plane): only dispatches fit and aggregates committed updates
      - Flower clients (compute plane): real training + comp energy/carbon metrics

    For each round:
      1) configure_fit -> ask Orchestrator who trains (dl_ok only) + fit_config per client
      2) aggregate_fit -> send client train metrics to Orchestrator, get committed client_ids
      3) aggregate only committed updates
      4) report global_model_norm back to Orchestrator finalize (server_round.csv, advance t_sim)
    """

    def __init__(self, orch_url: str) -> None:
        super().__init__()
        self.orch = OrchestratorHttpClient(orch_url, timeout_s=90.0)
        self.init_nd = np.zeros((10,), dtype=np.float32)

        # optional quick sanity
        try:
            h = self.orch.get("/health")
            print(f"[server] Orchestrator health: {h}")
        except Exception as e:
            print(f"[server] Orchestrator not reachable yet: {e}")

    def initialize_parameters(self, client_manager: ClientManager) -> Optional[Parameters]:
        return ndarrays_to_parameters([self.init_nd])

    def configure_fit(
        self,
        server_round: int,
        parameters: Parameters,
        client_manager: ClientManager,
    ) -> List[Tuple[fl.server.client_proxy.ClientProxy, FitIns]]:

        # All currently connected clients
        all_clients = list(client_manager.all().values())
        available_ids = [cp.cid for cp in all_clients]

        resp = self.orch.post("/v1/round/configure_fit", {
            "server_round": int(server_round),
            "available_client_ids": available_ids,
        })
        if not resp.get("ok", False):
            print(f"[server] configure_fit failed: {resp}")
            return []

        # Orchestrator returns only dl_ok assignments for training
        assignments = resp.get("train_assignments", [])
        by_cid = {cp.cid: cp for cp in all_clients}

        fit_instructions: List[Tuple[fl.server.client_proxy.ClientProxy, FitIns]] = []
        for a in assignments:
            cid = a.get("client_id", "")
            cfg = a.get("fit_config", {})
            cp = by_cid.get(cid)
            if cp is None:
                continue
            fit_instructions.append((cp, FitIns(parameters, cfg)))

        print(f"[round {server_round}] dispatch_fit={len(fit_instructions)} (from assignments={len(assignments)})")
        return fit_instructions

    def aggregate_fit(
        self,
        server_round: int,
        results: List[Tuple[fl.server.client_proxy.ClientProxy, FitRes]],
        failures,
    ) -> Tuple[Optional[Parameters], Dict]:

        # build payload to Orchestrator (control plane uses it to compute uplink start & commit/drop)
        fit_results_payload: List[dict] = []
        for cp, fitres in results:
            m = dict(fitres.metrics) if fitres.metrics else {}
            fit_results_payload.append({
                "client_id": cp.cid,
                "veh_id": str(m.get("veh_id", "")),
                "t_train_s": float(m.get("t_train_s", 0.0)),
                "e_comp_j": float(m.get("e_comp_j", 0.0)),
                "co2_comp_g": float(m.get("co2_comp_g", 0.0)),
                "num_examples": int(fitres.num_examples) if fitres.num_examples is not None else 1,
            })

        dec = self.orch.post("/v1/round/decide_commit", {
            "server_round": int(server_round),
            "fit_results": fit_results_payload,
        })
        if not dec.get("ok", False):
            print(f"[server] decide_commit failed: {dec}")
            committed = set()
        else:
            committed = set(dec.get("committed_client_ids", []))

        # Aggregate only committed
        if not committed:
            new_params = None
            global_norm = float("nan")
        else:
            weights: List[int] = []
            vecs: List[np.ndarray] = []
            for cp, fitres in results:
                if cp.cid not in committed:
                    continue
                nds = parameters_to_ndarrays(fitres.parameters)
                v = nds[0].astype(np.float32)
                n = int(fitres.num_examples) if fitres.num_examples is not None else 1
                weights.append(n)
                vecs.append(v * n)

            denom = float(sum(weights)) if weights else 1.0
            agg = np.sum(vecs, axis=0) / denom
            new_params = ndarrays_to_parameters([agg])
            global_norm = vec_norm(agg)

        # finalize round in Orchestrator (server_round.csv + advance t_sim happens there)
        fin = self.orch.post("/v1/round/finalize", {
            "server_round": int(server_round),
            "global_model_norm": float(global_norm),
        })
        if not fin.get("ok", False):
            print(f"[server] finalize failed: {fin}")

        return new_params, {"m_committed": len(committed), "global_model_norm": global_norm}

    # MVP: disable evaluate
    def configure_evaluate(self, server_round: int, parameters: Parameters, client_manager: ClientManager):
        return []

    def aggregate_evaluate(self, server_round: int, results, failures):
        return None, {}


def main() -> None:
    SERVER_ADDR = env_str("SERVER_ADDR", "0.0.0.0:8080")
    ROUNDS = env_int("ROUNDS", 10)
    ORCH_URL = env_str("ORCH_URL", "http://orchestrator:7070")

    strat = ProxyOrchestratedFedAvg(orch_url=ORCH_URL)

    fl.server.start_server(
        server_address=SERVER_ADDR,
        config=fl.server.ServerConfig(num_rounds=ROUNDS),
        strategy=strat,
    )


if __name__ == "__main__":
    main()
```

---

## fl/server_original_替换版本.py
<a id="flserveroriginal替换版本py"></a>

- Path: `/home/veins/fedits-tool/fl/server_original_替换版本.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import csv
import json
import time
from dataclasses import asdict
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import numpy as np
import flwr as fl
from flwr.common import (
    FitIns,
    FitRes,
    Parameters,
    ndarrays_to_parameters,
    parameters_to_ndarrays,
)
from flwr.server.client_manager import ClientManager

# Reuse your Veins client abstraction
from orchestrator.veins_client import (
    MockVeinsClient,
    RPCVeinsClient,
    DLResult,
    ULResult,
    VeinsState,
)

# -------------------------
# Helpers
# -------------------------

def run_id_now() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)

def joule_to_kwh(j: float) -> float:
    return j / 3_600_000.0

def comm_energy_j(p_rx_w: float, p_tx_w: float, t_down_s: float, t_up_s: float) -> float:
    return p_rx_w * max(t_down_s, 0.0) + p_tx_w * max(t_up_s, 0.0)

def comm_carbon_g(e_comm_j: float, ci_g_per_kwh: float) -> float:
    return joule_to_kwh(e_comm_j) * ci_g_per_kwh

def vec_norm(x: np.ndarray) -> float:
    return float(np.sqrt(np.sum(x * x)))

def env_float(name: str, default: float) -> float:
    try:
        return float(os.getenv(name, default))
    except Exception:
        return default

def env_int(name: str, default: int) -> int:
    try:
        return int(os.getenv(name, default))
    except Exception:
        return default

def env_str(name: str, default: str) -> str:
    return str(os.getenv(name, default))

# -------------------------
# CSV Loggers (append mode)
# -------------------------

class CsvAppender:
    def __init__(self, path: str, fieldnames: List[str]) -> None:
        self.path = path
        self.fieldnames = fieldnames
        ensure_dir(os.path.dirname(path))
        self._init_file()

    def _init_file(self) -> None:
        if not os.path.exists(self.path):
            with open(self.path, "w", newline="", encoding="utf-8") as f:
                w = csv.DictWriter(f, fieldnames=self.fieldnames)
                w.writeheader()

    def append_rows(self, rows: List[dict]) -> None:
        if not rows:
            return
        with open(self.path, "a", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=self.fieldnames)
            for r in rows:
                w.writerow(r)

# -------------------------
# Strategy with Orchestrator logic
# -------------------------

class OrchestratedFedAvg(fl.server.strategy.Strategy):
    """
    Flower server strategy embedding your orchestrator semantics:

    For each round:
      select (based on Veins in-range at t_sim)
      simulate downlink in Veins -> dl_done times
      train in real clients (Docker) -> returns t_train_s, e_comp_j, co2_comp_g
      simulate uplink in Veins starting at dl_done + t_train_s
      commit/drop based on uplink success + deadline
      aggregate only committed updates
      log clients_round.csv + server_round.csv
      advance virtual time: t_sim = deadline
    """

    def __init__(
        self,
        *,
        veins_mode: str,
        veins_host: str,
        veins_port: int,
        map_size_m: float,
        num_vehicles: int,
        rsu_x_m: float,
        rsu_y_m: float,
        rsu_radius_m: float,
        seed: int,
        rounds: int,
        m: int,
        deadline_s: float,
        model_down_bytes: int,
        model_up_bytes: int,
        ci_g_per_kwh: float,
        p_rx_w: float,
        p_tx_w: float,
        out_dir: str,
    ) -> None:
        super().__init__()
        self.seed = seed
        self.rounds = rounds
        self.m = m
        self.deadline_s = deadline_s
        self.model_down_bytes = model_down_bytes
        self.model_up_bytes = model_up_bytes
        self.ci_g_per_kwh = ci_g_per_kwh
        self.p_rx_w = p_rx_w
        self.p_tx_w = p_tx_w

        # virtual simulation time
        self.t_sim = 0.0

        # Veins client
        if veins_mode == "rpc":
            self.veins = RPCVeinsClient(host=veins_host, port=veins_port, timeout_s=15.0)
        else:
            self.veins = MockVeinsClient(
                map_size_m=map_size_m,
                num_vehicles=num_vehicles,
                rsu_x_m=rsu_x_m,
                rsu_y_m=rsu_y_m,
                rsu_radius_m=rsu_radius_m,
                seed=seed,
            )

        # output
        self.run_id = run_id_now()
        self.run_dir = os.path.join(out_dir, "runs", self.run_id)
        ensure_dir(self.run_dir)

        # snapshot config
        with open(os.path.join(self.run_dir, "config_snapshot.json"), "w", encoding="utf-8") as f:
            json.dump(
                {
                    "run_id": self.run_id,
                    "veins_mode": veins_mode,
                    "rsu": {"x": rsu_x_m, "y": rsu_y_m, "r": rsu_radius_m},
                    "map_size_m": map_size_m,
                    "num_vehicles": num_vehicles,
                    "seed": seed,
                    "rounds": rounds,
                    "m": m,
                    "deadline_s": deadline_s,
                    "model_down_bytes": model_down_bytes,
                    "model_up_bytes": model_up_bytes,
                    "ci_g_per_kwh": ci_g_per_kwh,
                    "p_rx_w": p_rx_w,
                    "p_tx_w": p_tx_w,
                },
                f,
                indent=2,
            )

        # CSV schemas
        self.clients_fields = [
            "run_id","round","client_id","veh_id",
            "selected","committed","drop_reason",
            "t_round_start","t_deadline",
            "t_dl_done","t_ul_start","t_ul_done",
            "t_down","t_train","t_up",
            "dl_ok","ul_ok",
            "dl_goodput_mbps","ul_goodput_mbps",
            "dl_rtt_ms","ul_rtt_ms",
            "e_comp_j","co2_comp_g",
            "e_comm_j","co2_comm_g","co2_total_g",
        ]
        self.server_fields = [
            "run_id","round",
            "m_selected","m_committed","dropout_rate",
            "global_model_norm",
            "co2_committed_g","co2_dropped_g","co2_total_g",
            "t_round_start","t_deadline",
        ]
        self.clients_csv = CsvAppender(os.path.join(self.run_dir, "clients_round.csv"), self.clients_fields)
        self.server_csv = CsvAppender(os.path.join(self.run_dir, "server_round.csv"), self.server_fields)

        # round context store
        self.ctx: Dict[int, dict] = {}

        # init model (10 dims)
        self.init_nd = np.zeros((10,), dtype=np.float32)

        print(f"[server] run_id={self.run_id} out={self.run_dir} veins_mode={veins_mode}")

    # ----- Strategy required methods -----

    def initialize_parameters(self, client_manager: ClientManager) -> Optional[Parameters]:
        return ndarrays_to_parameters([self.init_nd])

    def configure_fit(
        self,
        server_round: int,
        parameters: Parameters,
        client_manager: ClientManager,
    ) -> List[Tuple[fl.server.client_proxy.ClientProxy, FitIns]]:

        t_round_start = self.t_sim
        t_deadline = t_round_start + self.deadline_s

        # (1) Query Veins state
        state: VeinsState = self.veins.get_state(t=t_round_start)
        candidates_veh = [vid for vid, v in state.vehicles.items() if v.in_range]

        # (2) Choose veh_ids (random)
        rnd = np.random.RandomState(self.seed + server_round)
        if len(candidates_veh) <= self.m:
            selected_veh = candidates_veh
        else:
            selected_veh = list(rnd.choice(candidates_veh, size=self.m, replace=False))

        # (3) Map veh -> Flower clients (we just pick available clients 1-to-1)
        # We sample exactly len(selected_veh) Flower clients.
        available = list(client_manager.all().values())
        if len(available) == 0:
            return []
        if len(available) < len(selected_veh):
            selected_veh = selected_veh[:len(available)]

        rnd2 = np.random.RandomState(self.seed + 999 + server_round)
        chosen_clients = list(rnd2.choice(available, size=len(selected_veh), replace=False))

        veh_by_client: Dict[str, str] = {}
        for cp, veh in zip(chosen_clients, selected_veh):
            veh_by_client[cp.cid] = veh

        # (4) Downlink simulation in Veins (veh domain)
        dl = self.veins.simulate_downlink(
            t_now=t_round_start,
            veh_ids=selected_veh,
            size_bytes=self.model_down_bytes,
            deadline=t_deadline,
        )

        # Determine which veh got model successfully
        dl_ok_veh = [veh for veh in selected_veh if dl.get(veh) and dl[veh].ok]

        # Keep only clients whose mapped veh is dl_ok
        fit_instructions = []
        for cp in chosen_clients:
            veh = veh_by_client[cp.cid]
            dlr = dl.get(veh, DLResult.fail())
            if not dlr.ok:
                continue

            config = {
                "server_round": server_round,
                "veh_id": veh,
                "t_round_start": t_round_start,
                "t_deadline": t_deadline,
                # optional: you can pass model sizes for client-side logging
                "model_down_bytes": self.model_down_bytes,
                "model_up_bytes": self.model_up_bytes,
            }
            fit_instructions.append((cp, FitIns(parameters, config)))

        # Store ctx for aggregate_fit
        self.ctx[server_round] = {
            "t_round_start": t_round_start,
            "t_deadline": t_deadline,
            "veh_by_client": veh_by_client,
            "dl": dl,
            "selected_veh": selected_veh,
            "selected_client_cids": [cp.cid for cp in chosen_clients],
        }

        print(
            f"[round {server_round}] t={t_round_start:.2f} candVeh={len(candidates_veh)} "
            f"selVeh={len(selected_veh)} dlOK={len(fit_instructions)}"
        )

        return fit_instructions

    def aggregate_fit(
        self,
        server_round: int,
        results: List[Tuple[fl.server.client_proxy.ClientProxy, FitRes]],
        failures,
    ) -> Tuple[Optional[Parameters], Dict]:

        ctx = self.ctx.get(server_round, {})
        t_round_start = float(ctx.get("t_round_start", self.t_sim))
        t_deadline = float(ctx.get("t_deadline", t_round_start + self.deadline_s))
        veh_by_client = ctx.get("veh_by_client", {})
        dl: Dict[str, DLResult] = ctx.get("dl", {})

        # Parse client results
        # Each client returns: parameters + metrics(t_train_s, e_comp_j, co2_comp_g)
        train_metrics: Dict[str, dict] = {}
        params_by_client: Dict[str, List[np.ndarray]] = {}

        for cp, fitres in results:
            cid = cp.cid
            veh = veh_by_client.get(cid, "")
            m = dict(fitres.metrics) if fitres.metrics else {}
            t_train_s = float(m.get("t_train_s", 0.0))
            e_comp_j = float(m.get("e_comp_j", 0.0))
            co2_comp_g = float(m.get("co2_comp_g", 0.0))
            train_metrics[cid] = {
                "veh": veh,
                "t_train_s": t_train_s,
                "e_comp_j": e_comp_j,
                "co2_comp_g": co2_comp_g,
            }
            params_by_client[cid] = parameters_to_ndarrays(fitres.parameters)

        # Schedule uplink start times in veh domain
        ul_start_times_veh: Dict[str, float] = {}
        for cid, tm in train_metrics.items():
            veh = tm["veh"]
            dlr = dl.get(veh, DLResult.fail())
            if not dlr.ok:
                continue
            ul_start_times_veh[veh] = float(dlr.t_done) + float(tm["t_train_s"])

        # Simulate uplink in Veins
        ul: Dict[str, ULResult] = self.veins.simulate_uplink(
            start_times=ul_start_times_veh,
            veh_ids=list(ul_start_times_veh.keys()),
            size_bytes=self.model_up_bytes,
            deadline=t_deadline,
        )

        # Commit/drop
        committed_clients: List[str] = []
        dropped_clients: Dict[str, str] = {}
        co2_committed = 0.0
        co2_dropped = 0.0

        client_rows: List[dict] = []

        # For accounting, we also want to log selected but missing result clients
        selected_client_cids = ctx.get("selected_client_cids", [])
        all_considered = set(selected_client_cids) | set(train_metrics.keys())

        for cid in sorted(all_considered):
            veh = veh_by_client.get(cid, "")
            selected = 1

            dlr = dl.get(veh, DLResult.fail("dl_failed"))
            dl_ok = 1 if dlr.ok else 0

            tm = train_metrics.get(cid, None)
            if tm is None:
                # did not return fit result
                t_train_s = 0.0
                e_comp_j = 0.0
                co2_comp_g = 0.0
            else:
                t_train_s = float(tm["t_train_s"])
                e_comp_j = float(tm["e_comp_j"])
                co2_comp_g = float(tm["co2_comp_g"])

            t_dl_done = float(dlr.t_done) if dlr.ok else -1.0
            t_ul_start = (t_dl_done + t_train_s) if (dlr.ok and tm is not None) else -1.0

            ulr = ul.get(veh, ULResult.fail("ul_not_scheduled"))
            ul_ok = 1 if ulr.ok else 0
            t_ul_done = float(ulr.t_done) if ulr.ok else -1.0

            t_down = (t_dl_done - t_round_start) if dlr.ok else 0.0
            t_up = (t_ul_done - t_ul_start) if (ulr.ok and t_ul_start >= 0) else 0.0

            # Commit rule: uplink ok and <= deadline and has fit params
            if dlr.ok and (tm is not None) and ulr.ok and (t_ul_done <= t_deadline) and (cid in params_by_client):
                committed = 1
                drop_reason = ""
                committed_clients.append(cid)
            else:
                committed = 0
                if not dlr.ok:
                    drop_reason = dlr.reason or "dl_failed"
                elif tm is None:
                    drop_reason = "fit_missing"
                elif not ulr.ok:
                    drop_reason = ulr.reason or "ul_failed"
                else:
                    drop_reason = "deadline_miss"
                dropped_clients[cid] = drop_reason

            # comm energy/carbon
            e_comm_j = comm_energy_j(self.p_rx_w, self.p_tx_w, t_down, t_up)
            co2_comm_g = comm_carbon_g(e_comm_j, self.ci_g_per_kwh)
            co2_total_g = co2_comp_g + co2_comm_g

            if committed == 1:
                co2_committed += co2_total_g
            else:
                co2_dropped += co2_total_g

            client_rows.append({
                "run_id": self.run_id,
                "round": server_round,
                "client_id": cid,
                "veh_id": veh,
                "selected": selected,
                "committed": committed,
                "drop_reason": drop_reason,
                "t_round_start": t_round_start,
                "t_deadline": t_deadline,
                "t_dl_done": t_dl_done,
                "t_ul_start": t_ul_start,
                "t_ul_done": t_ul_done,
                "t_down": t_down,
                "t_train": t_train_s,
                "t_up": t_up,
                "dl_ok": dl_ok,
                "ul_ok": ul_ok,
                "dl_goodput_mbps": float(dlr.goodput_mbps),
                "ul_goodput_mbps": float(ulr.goodput_mbps),
                "dl_rtt_ms": float(dlr.rtt_ms),
                "ul_rtt_ms": float(ulr.rtt_ms),
                "e_comp_j": e_comp_j,
                "co2_comp_g": co2_comp_g,
                "e_comm_j": e_comm_j,
                "co2_comm_g": co2_comm_g,
                "co2_total_g": co2_total_g,
            })

        # Aggregate only committed updates (FedAvg weighted by num_examples if provided)
        if len(committed_clients) == 0:
            new_params = None
            global_norm = float("nan")
        else:
            # Each client sends a single ndarray (model vector)
            # We do simple mean (or weighted mean if 'num_examples' is provided)
            weights = []
            vecs = []
            for cp, fitres in results:
                cid = cp.cid
                if cid not in committed_clients:
                    continue
                nds = parameters_to_ndarrays(fitres.parameters)
                v = nds[0].astype(np.float32)
                num_ex = int(fitres.num_examples) if fitres.num_examples is not None else 1
                weights.append(num_ex)
                vecs.append(v * num_ex)

            denom = float(sum(weights)) if weights else 1.0
            agg = np.sum(vecs, axis=0) / denom
            new_params = ndarrays_to_parameters([agg])
            global_norm = vec_norm(agg)

        # Log
        self.clients_csv.append_rows(client_rows)

        m_selected = len(ctx.get("selected_client_cids", []))
        m_committed = len(committed_clients)
        dropout_rate = 0.0 if m_selected == 0 else (m_selected - m_committed) / float(m_selected)

        self.server_csv.append_rows([{
            "run_id": self.run_id,
            "round": server_round,
            "m_selected": m_selected,
            "m_committed": m_committed,
            "dropout_rate": dropout_rate,
            "global_model_norm": global_norm,
            "co2_committed_g": co2_committed,
            "co2_dropped_g": co2_dropped,
            "co2_total_g": co2_committed + co2_dropped,
            "t_round_start": t_round_start,
            "t_deadline": t_deadline,
        }])

        print(
            f"[round {server_round}] selectedClients={m_selected} committed={m_committed} "
            f"dropout={dropout_rate:.2f} model_norm={global_norm:.3f}"
        )

        # Advance virtual time to deadline
        self.t_sim = t_deadline

        return new_params, {"committed": m_committed, "dropout_rate": dropout_rate}

    # Disable evaluation for MVP
    def configure_evaluate(self, server_round: int, parameters: Parameters, client_manager: ClientManager):
        return []

    def aggregate_evaluate(self, server_round: int, results, failures):
        return None, {}


def main() -> None:
    # ---- env config (easy to tweak from docker-compose) ----
    OUT_DIR = env_str("OUT_DIR", "outputs")

    VEINS_MODE = env_str("VEINS_MODE", "mock")   # mock | rpc
    VEINS_HOST = env_str("VEINS_HOST", "127.0.0.1")
    VEINS_PORT = env_int("VEINS_PORT", 9999)

    MAP_SIZE_M = env_float("MAP_SIZE_M", 1000.0)
    NUM_VEH = env_int("NUM_VEH", 100)
    RSU_X = env_float("RSU_X_M", 500.0)
    RSU_Y = env_float("RSU_Y_M", 500.0)
    RSU_R = env_float("RSU_R_M", 300.0)

    SEED = env_int("SEED", 42)
    ROUNDS = env_int("ROUNDS", 5)
    M = env_int("M", 10)
    DEADLINE_S = env_float("DEADLINE_S", 25.0)

    MODEL_DOWN = env_int("MODEL_DOWN_BYTES", 2_000_000)
    MODEL_UP = env_int("MODEL_UP_BYTES", 2_000_000)

    CI = env_float("CI_G_PER_KWH", 200.0)
    P_RX = env_float("P_RX_W", 1.0)
    P_TX = env_float("P_TX_W", 1.5)

    SERVER_ADDR = env_str("SERVER_ADDR", "0.0.0.0:8080")

    strat = OrchestratedFedAvg(
        veins_mode=VEINS_MODE,
        veins_host=VEINS_HOST,
        veins_port=VEINS_PORT,
        map_size_m=MAP_SIZE_M,
        num_vehicles=NUM_VEH,
        rsu_x_m=RSU_X,
        rsu_y_m=RSU_Y,
        rsu_radius_m=RSU_R,
        seed=SEED,
        rounds=ROUNDS,
        m=M,
        deadline_s=DEADLINE_S,
        model_down_bytes=MODEL_DOWN,
        model_up_bytes=MODEL_UP,
        ci_g_per_kwh=CI,
        p_rx_w=P_RX,
        p_tx_w=P_TX,
        out_dir=OUT_DIR,
    )

    # Start Flower server (deprecated warning is OK for MVP)
    fl.server.start_server(
        server_address=SERVER_ADDR,
        config=fl.server.ServerConfig(num_rounds=ROUNDS),
        strategy=strat,
    )


if __name__ == "__main__":
    main()
```

---

## Makefile
<a id="makefile"></a>

- Path: `/home/veins/fedits-tool/Makefile`
```makefile

```

---

## orchestrator/__init__.py
<a id="orchestratorinitpy"></a>

- Path: `/home/veins/fedits-tool/orchestrator/__init__.py`
```python

```

---

## orchestrator/flwr_adapter.py
<a id="orchestratorflwradapterpy"></a>

- Path: `/home/veins/fedits-tool/orchestrator/flwr_adapter.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Flower adapter layer.

For now: MockFlwrAdapter to run end-to-end immediately.
Later: replace with real Flower/Docker integration.

Contract:
train_clients(round_idx, client_ids, global_model, ci_g_per_kwh) -> Dict[client_id, TrainResult]
"""

from __future__ import annotations

import random
from dataclasses import dataclass
from typing import Dict, List


@dataclass
class TrainResult:
    t_train_s: float
    e_comp_j: float
    co2_comp_g: float
    update_vec: List[float]


class MockFlwrAdapter:
    """
    Mock training:
    - t_train depends on client id and round (random but stable with seed)
    - update is small random vector
    - compute energy: P_comp * t_train
    - compute carbon: E(kWh) * CI
    """

    def __init__(self, seed: int = 42, p_comp_w: float = 18.0) -> None:
        self.seed = seed
        self.p_comp_w = float(p_comp_w)  # average compute power (W) for mock

    @staticmethod
    def _joule_to_kwh(j: float) -> float:
        return j / 3_600_000.0

    def train_clients(
        self,
        round_idx: int,
        client_ids: List[str],
        global_model: List[float],
        ci_g_per_kwh: float,
    ) -> Dict[str, TrainResult]:
        out: Dict[str, TrainResult] = {}

        for cid in client_ids:
            # deterministic randomness per (seed, round, client)
            rnd = random.Random(hash((self.seed, round_idx, cid)) & 0xFFFFFFFF)

            # training time: 2~8 seconds (mock)
            t_train = rnd.uniform(2.0, 8.0)

            # compute energy
            e_comp_j = self.p_comp_w * t_train

            # compute carbon
            co2_comp_g = self._joule_to_kwh(e_comp_j) * float(ci_g_per_kwh)

            # toy update vector: small perturbation
            dim = len(global_model)
            update = [rnd.uniform(-0.05, 0.05) for _ in range(dim)]

            out[cid] = TrainResult(
                t_train_s=t_train,
                e_comp_j=e_comp_j,
                co2_comp_g=co2_comp_g,
                update_vec=update,
            )

        return out
```

---

## orchestrator/orch_core.py
<a id="orchestratororchcorepy"></a>

- Path: `/home/veins/fedits-tool/orchestrator/orch_core.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

import json, os, csv, random, re
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any

from orchestrator.veins_client import MockVeinsClient, RPCVeinsClient, VeinsState, DLResult, ULResult, BaseVeinsClient


def run_id_now() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")

def ensure_dir(p: str) -> None:
    os.makedirs(p, exist_ok=True)

def joule_to_kwh(j: float) -> float:
    return j / 3_600_000.0

def comm_energy_j(p_rx_w: float, p_tx_w: float, t_down_s: float, t_up_s: float) -> float:
    return p_rx_w * max(t_down_s, 0.0) + p_tx_w * max(t_up_s, 0.0)

def comm_carbon_g(e_comm_j: float, ci_g_per_kwh: float) -> float:
    return joule_to_kwh(e_comm_j) * ci_g_per_kwh


class CsvAppender:
    def __init__(self, path: str, fieldnames: List[str]) -> None:
        self.path = path
        self.fieldnames = fieldnames
        ensure_dir(os.path.dirname(path))
        if not os.path.exists(self.path):
            with open(self.path, "w", newline="", encoding="utf-8") as f:
                w = csv.DictWriter(f, fieldnames=self.fieldnames)
                w.writeheader()

    def append_rows(self, rows: List[dict]) -> None:
        if not rows:
            return
        with open(self.path, "a", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=self.fieldnames)
            for r in rows:
                w.writerow(r)


@dataclass
class OrchestratorConfig:
    # sim
    map_size_m: float = 1000.0
    num_vehicles: int = 100
    rsu_x_m: float = 500.0
    rsu_y_m: float = 500.0
    rsu_radius_m: float = 300.0

    # fl
    rounds: int = 10
    clients_per_round: int = 10
    deadline_s: float = 25.0
    model_down_bytes: int = 2_000_000
    model_up_bytes: int = 2_000_000

    # carbon + radio power
    ci_g_per_kwh: float = 200.0
    p_rx_w: float = 1.0
    p_tx_w: float = 1.5

    # misc
    seed: int = 42
    out_dir: str = "outputs"
    veins_mode: str = "mock"   # mock | rpc
    veins_host: str = "127.0.0.1"
    veins_port: int = 9999


class OrchestratorCore:
    """
    Strict control-plane core:
    - Talks to Veins (mock or rpc) for reachability + downlink/uplink timing + success reason.
    - Talks to Flower server via HTTP service (handled in orch_service.py).
    - Does NOT aggregate model weights (server does), but decides commit/drop and logs.
    """

    def __init__(self, cfg: OrchestratorConfig) -> None:
        self.cfg = cfg
        self.run_id = run_id_now()
        self.t_sim = 0.0  # virtual sim time

        # output
        self.run_dir = os.path.join(cfg.out_dir, "runs", self.run_id)
        ensure_dir(self.run_dir)
        with open(os.path.join(self.run_dir, "config_snapshot.json"), "w", encoding="utf-8") as f:
            json.dump({"run_id": self.run_id, "cfg": cfg.__dict__}, f, indent=2)

        # csv schema (match your existing fields)
        self.clients_fields = [
            "run_id","round","client_id","veh_id",
            "selected","committed","drop_reason",
            "t_round_start","t_deadline",
            "t_dl_done","t_ul_start","t_ul_done",
            "t_down","t_train","t_up",
            "dl_ok","ul_ok",
            "dl_goodput_mbps","ul_goodput_mbps",
            "dl_rtt_ms","ul_rtt_ms",
            "e_comp_j","co2_comp_g",
            "e_comm_j","co2_comm_g","co2_total_g",
        ]
        self.server_fields = [
            "run_id","round",
            "m_selected","m_committed","dropout_rate",
            "global_model_norm",
            "co2_committed_g","co2_dropped_g","co2_total_g",
            "t_round_start","t_deadline",
        ]
        self.clients_csv = CsvAppender(os.path.join(self.run_dir, "clients_round.csv"), self.clients_fields)
        self.server_csv = CsvAppender(os.path.join(self.run_dir, "server_round.csv"), self.server_fields)

        # veins client
        if cfg.veins_mode == "rpc":
            self.veins: BaseVeinsClient = RPCVeinsClient(cfg.veins_host, cfg.veins_port, timeout_s=30.0)
        else:
            self.veins = MockVeinsClient(
                map_size_m=cfg.map_size_m,
                num_vehicles=cfg.num_vehicles,
                rsu_x_m=cfg.rsu_x_m,
                rsu_y_m=cfg.rsu_y_m,
                rsu_radius_m=cfg.rsu_radius_m,
                seed=cfg.seed,
            )

        # per-round context (control-plane memory)
        self.ctx: Dict[int, Dict[str, Any]] = {}

        print(f"[orch-core] run_id={self.run_id} out={self.run_dir} veins_mode={cfg.veins_mode}")

    # ---------- binding: veh_id -> client_id ----------
    def bind_veh_to_client(self, veh_id: str) -> str:
        # default: veh17 -> client17 (2-digit) ; if >=100 use 3-digit
        m = re.search(r"(\d+)", veh_id)
        if m:
            n = int(m.group(1))
        else:
            n = abs(hash(veh_id)) % max(self.cfg.num_vehicles, 1)
        if n <= 99:
            return f"client{n:02d}"
        return f"client{n:03d}"

    # ---------- round APIs used by Flower Strategy ----------
    def configure_fit(self, server_round: int, available_client_ids: List[str]) -> Dict[str, Any]:
        t_round_start = self.t_sim
        t_deadline = t_round_start + self.cfg.deadline_s

        state: VeinsState = self.veins.get_state(t=t_round_start)
        candidates_veh = [vid for vid, v in state.vehicles.items() if v.in_range]

        available = set(available_client_ids)
        candidate_pairs: List[Tuple[str,str]] = []  # (cid, veh)
        for veh in candidates_veh:
            cid = self.bind_veh_to_client(veh)
            if cid in available:
                candidate_pairs.append((cid, veh))

        rnd = random.Random(self.cfg.seed + server_round)
        if len(candidate_pairs) <= self.cfg.clients_per_round:
            selected_pairs = candidate_pairs[:]
        else:
            selected_pairs = rnd.sample(candidate_pairs, self.cfg.clients_per_round)

        veh_ids = [veh for cid, veh in selected_pairs]

        dl = self.veins.simulate_downlink(
            t_now=t_round_start,
            veh_ids=veh_ids,
            size_bytes=self.cfg.model_down_bytes,
            deadline=t_deadline,
        )

        # only dl_ok clients actually train
        assignments: List[dict] = []
        for cid, veh in selected_pairs:
            dlr = dl.get(veh, DLResult.fail("dl_no_result"))
            if dlr.ok:
                assignments.append({
                    "client_id": cid,
                    "veh_id": veh,
                    "fit_config": {
                        "veh_id": veh,
                        "ci_g_per_kwh": self.cfg.ci_g_per_kwh,
                        "t_round_start": t_round_start,
                        "t_deadline": t_deadline,
                        "server_round": server_round,
                    }
                })

        # store ctx for later commit decision & logging
        self.ctx[server_round] = {
            "t_round_start": t_round_start,
            "t_deadline": t_deadline,
            "selected_pairs": selected_pairs,   # includes dl_fail
            "dl": dl,
            "pending_server_row": None,
        }

        return {
            "ok": True,
            "run_id": self.run_id,
            "t_round_start": t_round_start,
            "t_deadline": t_deadline,
            "selected": [{"client_id": cid, "veh_id": veh} for cid, veh in selected_pairs],
            "train_assignments": assignments,   # only dl_ok
        }

    def decide_commit(self, server_round: int, fit_results: List[dict]) -> Dict[str, Any]:
        if server_round not in self.ctx:
            return {"ok": False, "error": f"no ctx for round {server_round}"}
        ctx = self.ctx[server_round]
        t_round_start = float(ctx["t_round_start"])
        t_deadline = float(ctx["t_deadline"])
        selected_pairs: List[Tuple[str,str]] = ctx["selected_pairs"]
        dl: Dict[str, DLResult] = ctx["dl"]

        # map metrics by client_id
        m_by_cid: Dict[str, dict] = {}
        for r in fit_results:
            cid = str(r.get("client_id", ""))
            m_by_cid[cid] = r

        # uplink start times are per-veh (veh_id)
        start_times: Dict[str, float] = {}
        ul_veh_ids: List[str] = []

        for cid, veh in selected_pairs:
            dlr = dl.get(veh, DLResult.fail("dl_no_result"))
            mr = m_by_cid.get(cid)
            if dlr.ok and mr:
                t_train = float(mr.get("t_train_s", 0.0))
                start = float(dlr.t_done) + t_train
                start_times[veh] = start
                ul_veh_ids.append(veh)

        ul = self.veins.simulate_uplink(
            start_times=start_times,
            veh_ids=ul_veh_ids,
            size_bytes=self.cfg.model_up_bytes,
            deadline=t_deadline,
        )

        committed_cids: List[str] = []
        client_rows: List[dict] = []

        co2_committed = 0.0
        co2_dropped = 0.0

        for cid, veh in selected_pairs:
            dlr = dl.get(veh, DLResult.fail("dl_no_result"))
            mr = m_by_cid.get(cid)
            ulr = ul.get(veh, ULResult.fail("not_scheduled"))

            selected = 1
            dl_ok = 1 if dlr.ok else 0

            t_dl_done = float(dlr.t_done) if dlr.ok else -1.0
            t_train = float(mr.get("t_train_s", 0.0)) if mr else 0.0

            if dlr.ok and mr:
                t_ul_start = float(start_times.get(veh, -1.0))
            else:
                t_ul_start = -1.0

            ul_ok = 1 if ulr.ok else 0
            t_ul_done = float(ulr.t_done) if ulr.ok else -1.0

            # durations
            t_down = (t_dl_done - t_round_start) if dlr.ok else 0.0
            t_up = (t_ul_done - t_ul_start) if (ulr.ok and t_ul_start >= 0.0) else 0.0

            # energy/carbon
            e_comp_j = float(mr.get("e_comp_j", 0.0)) if mr else 0.0
            co2_comp_g = float(mr.get("co2_comp_g", 0.0)) if mr else 0.0

            e_comm_j = comm_energy_j(self.cfg.p_rx_w, self.cfg.p_tx_w, t_down, t_up)
            co2_comm_g = comm_carbon_g(e_comm_j, self.cfg.ci_g_per_kwh)
            co2_total = co2_comp_g + co2_comm_g

            # commit/drop semantics
            committed = 0
            drop_reason = ""

            if not dlr.ok:
                drop_reason = dlr.reason or "dl_failed"
            elif mr is None:
                drop_reason = "train_missing"
            elif not ulr.ok:
                drop_reason = ulr.reason or "ul_failed"
            elif float(ulr.t_done) > t_deadline:
                drop_reason = "ul_deadline_miss"
            else:
                committed = 1
                committed_cids.append(cid)

            if committed == 1:
                co2_committed += co2_total
            else:
                co2_dropped += co2_total

            client_rows.append({
                "run_id": self.run_id,
                "round": server_round,
                "client_id": cid,
                "veh_id": veh,
                "selected": selected,
                "committed": committed,
                "drop_reason": drop_reason,
                "t_round_start": t_round_start,
                "t_deadline": t_deadline,
                "t_dl_done": t_dl_done,
                "t_ul_start": t_ul_start,
                "t_ul_done": t_ul_done,
                "t_down": t_down,
                "t_train": t_train,
                "t_up": t_up,
                "dl_ok": dl_ok,
                "ul_ok": ul_ok,
                "dl_goodput_mbps": float(dlr.goodput_mbps),
                "ul_goodput_mbps": float(ulr.goodput_mbps),
                "dl_rtt_ms": float(dlr.rtt_ms),
                "ul_rtt_ms": float(ulr.rtt_ms),
                "e_comp_j": e_comp_j,
                "co2_comp_g": co2_comp_g,
                "e_comm_j": e_comm_j,
                "co2_comm_g": co2_comm_g,
                "co2_total_g": co2_total,
            })

        # write per-client rows now (strictly control-plane output)
        self.clients_csv.append_rows(client_rows)

        m_selected = len(selected_pairs)
        m_committed = len(committed_cids)
        dropout_rate = 0.0 if m_selected == 0 else (m_selected - m_committed) / float(m_selected)

        # store pending server row (needs global_model_norm from server finalize)
        ctx["pending_server_row"] = {
            "run_id": self.run_id,
            "round": server_round,
            "m_selected": m_selected,
            "m_committed": m_committed,
            "dropout_rate": dropout_rate,
            "global_model_norm": float("nan"),
            "co2_committed_g": co2_committed,
            "co2_dropped_g": co2_dropped,
            "co2_total_g": co2_committed + co2_dropped,
            "t_round_start": t_round_start,
            "t_deadline": t_deadline,
        }

        return {"ok": True, "committed_client_ids": committed_cids}

    def finalize_round(self, server_round: int, global_model_norm: float) -> Dict[str, Any]:
        if server_round not in self.ctx:
            return {"ok": False, "error": f"no ctx for round {server_round}"}
        ctx = self.ctx[server_round]
        row = ctx.get("pending_server_row")
        if not row:
            return {"ok": False, "error": f"no pending_server_row for round {server_round}"}

        row["global_model_norm"] = float(global_model_norm)
        self.server_csv.append_rows([row])

        # advance virtual time: end at deadline
        self.t_sim = float(ctx["t_deadline"])

        return {"ok": True, "t_sim": self.t_sim, "run_id": self.run_id}
```

---

## orchestrator/orch_http_client.py
<a id="orchestratororchhttpclientpy"></a>

- Path: `/home/veins/fedits-tool/orchestrator/orch_http_client.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import urllib.request
from typing import Any, Dict


class OrchestratorHttpClient:
    def __init__(self, base_url: str, timeout_s: float = 30.0) -> None:
        self.base_url = base_url.rstrip("/")
        self.timeout_s = float(timeout_s)

    def post(self, path: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        url = self.base_url + path
        data = json.dumps(payload).encode("utf-8")
        req = urllib.request.Request(url, data=data, method="POST")
        req.add_header("Content-Type", "application/json")
        with urllib.request.urlopen(req, timeout=self.timeout_s) as resp:
            text = resp.read().decode("utf-8").strip()
            return json.loads(text) if text else {}

    def get(self, path: str) -> Dict[str, Any]:
        url = self.base_url + path
        with urllib.request.urlopen(url, timeout=self.timeout_s) as resp:
            text = resp.read().decode("utf-8").strip()
            return json.loads(text) if text else {}
```

---

## orchestrator/orch_service.py
<a id="orchestratororchservicepy"></a>

- Path: `/home/veins/fedits-tool/orchestrator/orch_service.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
from __future__ import annotations

import json, os
from http.server import BaseHTTPRequestHandler, ThreadingHTTPServer
from typing import Any, Dict

from orchestrator.orch_core import OrchestratorCore, OrchestratorConfig


def env_str(k: str, d: str) -> str:
    return str(os.getenv(k, d))

def env_int(k: str, d: int) -> int:
    try: return int(os.getenv(k, d))
    except: return d

def env_float(k: str, d: float) -> float:
    try: return float(os.getenv(k, d))
    except: return d


def load_cfg_from_env() -> OrchestratorConfig:
    return OrchestratorConfig(
        map_size_m=env_float("MAP_SIZE_M", 1000.0),
        num_vehicles=env_int("NUM_VEH", 100),
        rsu_x_m=env_float("RSU_X_M", 500.0),
        rsu_y_m=env_float("RSU_Y_M", 500.0),
        rsu_radius_m=env_float("RSU_R_M", 300.0),
        rounds=env_int("ROUNDS", 10),
        clients_per_round=env_int("M", 10),
        deadline_s=env_float("DEADLINE_S", 25.0),
        model_down_bytes=env_int("MODEL_DOWN_BYTES", 2_000_000),
        model_up_bytes=env_int("MODEL_UP_BYTES", 2_000_000),
        ci_g_per_kwh=env_float("CI_G_PER_KWH", 200.0),
        p_rx_w=env_float("P_RX_W", 1.0),
        p_tx_w=env_float("P_TX_W", 1.5),
        seed=env_int("SEED", 42),
        out_dir=env_str("OUT_DIR", "outputs"),
        veins_mode=env_str("VEINS_MODE", "mock"),
        veins_host=env_str("VEINS_HOST", "127.0.0.1"),
        veins_port=env_int("VEINS_PORT", 9999),
    )


class Handler(BaseHTTPRequestHandler):
    core: OrchestratorCore = None  # type: ignore

    def _json(self, code: int, obj: Dict[str, Any]) -> None:
        b = (json.dumps(obj) + "\n").encode("utf-8")
        self.send_response(code)
        self.send_header("Content-Type", "application/json")
        self.send_header("Content-Length", str(len(b)))
        self.end_headers()
        self.wfile.write(b)

    def do_GET(self) -> None:
        if self.path == "/health":
            self._json(200, {"ok": True, "run_id": self.core.run_id, "t_sim": self.core.t_sim})
        else:
            self._json(404, {"ok": False, "error": "not found"})

    def do_POST(self) -> None:
        try:
            n = int(self.headers.get("Content-Length", "0"))
            raw = self.rfile.read(n).decode("utf-8")
            req = json.loads(raw) if raw.strip() else {}
        except Exception as e:
            return self._json(400, {"ok": False, "error": f"bad json: {e}"})

        if self.path == "/v1/round/configure_fit":
            resp = self.core.configure_fit(
                server_round=int(req.get("server_round", 0)),
                available_client_ids=list(req.get("available_client_ids", [])),
            )
            return self._json(200, resp)

        if self.path == "/v1/round/decide_commit":
            resp = self.core.decide_commit(
                server_round=int(req.get("server_round", 0)),
                fit_results=list(req.get("fit_results", [])),
            )
            return self._json(200, resp)

        if self.path == "/v1/round/finalize":
            resp = self.core.finalize_round(
                server_round=int(req.get("server_round", 0)),
                global_model_norm=float(req.get("global_model_norm", float("nan"))),
            )
            return self._json(200, resp)

        return self._json(404, {"ok": False, "error": "not found"})


def main() -> None:
    host = env_str("ORCH_HOST", "0.0.0.0")
    port = env_int("ORCH_PORT", 7070)

    cfg = load_cfg_from_env()
    core = OrchestratorCore(cfg)
    Handler.core = core

    httpd = ThreadingHTTPServer((host, port), Handler)
    print(f"[orch-service] listening on http://{host}:{port}")
    httpd.serve_forever()


if __name__ == "__main__":
    main()
```

---

## orchestrator/orchestrator.py
<a id="orchestratororchestratorpy"></a>

- Path: `/home/veins/fedits-tool/orchestrator/orchestrator.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Orchestrator: round state machine
select → downlink(sim) → train(real/mock) → uplink(sim) → commit/drop → aggregate → log

Default mode is MOCK so you can run immediately without Veins/Flower integration.
Later, switch to --mode rpc and implement the Veins ControlServer side.

Outputs:
- outputs/runs/<run_id>/clients_round.csv
- outputs/runs/<run_id>/server_round.csv
"""

from __future__ import annotations

import argparse
import csv
import json
import os
import sys
import time
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Dict, List, Tuple, Optional

# Make local imports work even when run as a script
THIS_DIR = os.path.dirname(os.path.abspath(__file__))
if THIS_DIR not in sys.path:
    sys.path.insert(0, THIS_DIR)

from veins_client import MockVeinsClient, RPCVeinsClient, VeinsState, DLResult, ULResult
from flwr_adapter import MockFlwrAdapter, TrainResult


# -----------------------------
# Config + Data Structures
# -----------------------------

@dataclass
class RsuConfig:
    x_m: float = 500.0
    y_m: float = 500.0
    radius_m: float = 300.0


@dataclass
class SimConfig:
    map_size_m: float = 1000.0             # 1km x 1km
    num_vehicles: int = 100
    rsu: RsuConfig = RsuConfig()

    rounds: int = 10
    clients_per_round: int = 10            # m
    round_deadline_s: float = 25.0         # virtual deadline length

    # payload sizes (bytes) - adjust later based on model
    model_down_bytes: int = 2_000_000      # ~2MB
    model_up_bytes: int = 2_000_000        # ~2MB

    # carbon-intensity for mock (gCO2/kWh). Replace with your CI trace later.
    ci_g_per_kwh: float = 200.0

    # simple radio power model for comm carbon (Watts)
    p_rx_w: float = 1.0
    p_tx_w: float = 1.5

    # selection policy
    selection: str = "random"              # for now: random from in-range candidates

    seed: int = 42


@dataclass
class ClientRoundRow:
    run_id: str
    round: int
    veh_id: str

    selected: int
    committed: int
    drop_reason: str

    # virtual time stamps
    t_round_start: float
    t_dl_done: float
    t_ul_start: float
    t_ul_done: float

    # durations
    t_down: float
    t_train: float
    t_up: float

    # link metrics (from Veins)
    dl_ok: int
    ul_ok: int
    dl_goodput_mbps: float
    ul_goodput_mbps: float
    dl_rtt_ms: float
    ul_rtt_ms: float

    # energy/carbon accounting
    e_comp_j: float
    co2_comp_g: float

    e_comm_j: float
    co2_comm_g: float

    co2_total_g: float


@dataclass
class ServerRoundRow:
    run_id: str
    round: int

    m_selected: int
    m_committed: int
    dropout_rate: float

    # basic model value (toy)
    global_model_norm: float

    # carbon summary
    co2_committed_g: float
    co2_dropped_g: float
    co2_total_g: float


# -----------------------------
# Helpers
# -----------------------------

def now_run_id() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def ensure_dir(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def write_csv(path: str, rows: List[dict], fieldnames: List[str]) -> None:
    ensure_dir(os.path.dirname(path))
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=fieldnames)
        w.writeheader()
        for r in rows:
            w.writerow(r)


def joule_to_kwh(j: float) -> float:
    # 1 kWh = 3.6e6 Joules
    return j / 3_600_000.0


def comm_energy_j(p_rx_w: float, p_tx_w: float, t_down_s: float, t_up_s: float) -> float:
    return p_rx_w * max(t_down_s, 0.0) + p_tx_w * max(t_up_s, 0.0)


def comm_carbon_g(e_comm_j: float, ci_g_per_kwh: float) -> float:
    return joule_to_kwh(e_comm_j) * ci_g_per_kwh


def vec_norm(v: List[float]) -> float:
    return sum(x * x for x in v) ** 0.5


def aggregate_updates(global_model: List[float], updates: Dict[str, List[float]]) -> List[float]:
    """Toy aggregator: global_model + mean(update)"""
    if not updates:
        return global_model
    dim = len(global_model)
    mean_upd = [0.0] * dim
    for upd in updates.values():
        for i in range(dim):
            mean_upd[i] += upd[i]
    n = float(len(updates))
    mean_upd = [x / n for x in mean_upd]
    return [global_model[i] + mean_upd[i] for i in range(dim)]


# -----------------------------
# Selection
# -----------------------------

def select_clients(cfg: SimConfig, candidates: List[str]) -> List[str]:
    # for MVP: random sampling from candidates
    import random
    rnd = random.Random(cfg.seed + len(candidates))
    if len(candidates) <= cfg.clients_per_round:
        return candidates[:]
    return rnd.sample(candidates, cfg.clients_per_round)


# -----------------------------
# Main Orchestrator
# -----------------------------

def run(cfg: SimConfig, mode: str, host: str, port: int, out_root: str) -> None:
    run_id = now_run_id()
    print(f"[orchestrator] run_id={run_id} mode={mode}")

    run_dir = os.path.join(out_root, "runs", run_id)
    ensure_dir(run_dir)

    # Save config snapshot for reproducibility
    cfg_path = os.path.join(run_dir, "config_snapshot.json")
    with open(cfg_path, "w", encoding="utf-8") as f:
        json.dump({
            "SimConfig": asdict(cfg),
        }, f, indent=2)
    print(f"[orchestrator] saved config: {cfg_path}")

    # Veins client
    if mode == "rpc":
        veins = RPCVeinsClient(host=host, port=port, timeout_s=10.0)
    else:
        veins = MockVeinsClient(
            map_size_m=cfg.map_size_m,
            num_vehicles=cfg.num_vehicles,
            rsu_x_m=cfg.rsu.x_m,
            rsu_y_m=cfg.rsu.y_m,
            rsu_radius_m=cfg.rsu.radius_m,
            seed=cfg.seed,
        )

    # Flower adapter (mock for now)
    fl = MockFlwrAdapter(seed=cfg.seed)

    # A toy global model vector (10 dims)
    global_model = [0.0] * 10

    clients_rows: List[dict] = []
    server_rows: List[dict] = []

    # Virtual simulation time
    t_sim = 0.0

    for r in range(1, cfg.rounds + 1):
        t_round_start = t_sim
        t_deadline = t_round_start + cfg.round_deadline_s

        # 1) query Veins state (positions + inRange)
        state: VeinsState = veins.get_state(t=t_round_start)
        candidates = [vid for vid, v in state.vehicles.items() if v.in_range]
        selected = select_clients(cfg, candidates)

        # 2) simulate downlink
        dl: Dict[str, DLResult] = veins.simulate_downlink(
            t_now=t_round_start,
            veh_ids=selected,
            size_bytes=cfg.model_down_bytes,
            deadline=t_deadline,
        )

        # clients that successfully received model before deadline
        dl_ok_ids = [vid for vid in selected if dl.get(vid) and dl[vid].ok]

        # 3) train (real/mock)
        train_res: Dict[str, TrainResult] = fl.train_clients(
            round_idx=r,
            client_ids=dl_ok_ids,
            global_model=global_model,
            ci_g_per_kwh=cfg.ci_g_per_kwh,
        )

        # 4) schedule uplink start times based on dl_done + T_train
        ul_start_times: Dict[str, float] = {}
        for vid in dl_ok_ids:
            t_dl_done = dl[vid].t_done
            t_train = train_res[vid].t_train_s
            ul_start_times[vid] = t_dl_done + t_train

        # 5) simulate uplink
        ul: Dict[str, ULResult] = veins.simulate_uplink(
            start_times=ul_start_times,
            veh_ids=dl_ok_ids,
            size_bytes=cfg.model_up_bytes,
            deadline=t_deadline,
        )

        # 6) commit/drop + aggregate
        committed_updates: Dict[str, List[float]] = {}
        co2_committed = 0.0
        co2_dropped = 0.0

        for vid in selected:
            dlr = dl.get(vid, DLResult.fail())
            tr = train_res.get(vid)  # only exists if dl ok
            ulr = ul.get(vid, ULResult.fail(reason="not_scheduled"))

            selected_flag = 1
            dl_ok = 1 if dlr.ok else 0

            # compute times
            t_dl_done = dlr.t_done if dlr.ok else -1.0
            t_train = tr.t_train_s if tr else 0.0

            if dlr.ok and tr:
                t_ul_start = ul_start_times[vid]
            else:
                t_ul_start = -1.0

            t_ul_done = ulr.t_done if ulr.ok else -1.0
            ul_ok = 1 if ulr.ok else 0

            # duration
            t_down = (t_dl_done - t_round_start) if dlr.ok else 0.0
            t_up = (t_ul_done - t_ul_start) if (ulr.ok and t_ul_start >= 0) else 0.0

            # commit rule (MVP): ul ok AND arrives before deadline
            if dlr.ok and tr and ulr.ok and (t_ul_done <= t_deadline):
                committed = 1
                drop_reason = ""
                committed_updates[vid] = tr.update_vec
            else:
                committed = 0
                if not dlr.ok:
                    drop_reason = dlr.reason or "dl_failed"
                elif tr is None:
                    drop_reason = "train_missing"
                elif not ulr.ok:
                    drop_reason = ulr.reason or "ul_failed"
                else:
                    drop_reason = "deadline_miss"

            # energy/carbon
            e_comp_j = tr.e_comp_j if tr else 0.0
            co2_comp_g = tr.co2_comp_g if tr else 0.0

            e_comm_j = comm_energy_j(cfg.p_rx_w, cfg.p_tx_w, t_down, t_up)
            co2_comm_g = comm_carbon_g(e_comm_j, cfg.ci_g_per_kwh)
            co2_total_g = co2_comp_g + co2_comm_g

            # bookkeep committed vs dropped carbon (total carbon happened; but "useful" is committed)
            if committed == 1:
                co2_committed += co2_total_g
            else:
                co2_dropped += co2_total_g

            row = ClientRoundRow(
                run_id=run_id,
                round=r,
                veh_id=vid,
                selected=selected_flag,
                committed=committed,
                drop_reason=drop_reason,
                t_round_start=t_round_start,
                t_dl_done=t_dl_done,
                t_ul_start=t_ul_start,
                t_ul_done=t_ul_done,
                t_down=t_down,
                t_train=t_train,
                t_up=t_up,
                dl_ok=dl_ok,
                ul_ok=ul_ok,
                dl_goodput_mbps=dlr.goodput_mbps,
                ul_goodput_mbps=ulr.goodput_mbps,
                dl_rtt_ms=dlr.rtt_ms,
                ul_rtt_ms=ulr.rtt_ms,
                e_comp_j=e_comp_j,
                co2_comp_g=co2_comp_g,
                e_comm_j=e_comm_j,
                co2_comm_g=co2_comm_g,
                co2_total_g=co2_total_g,
            )
            clients_rows.append(asdict(row))

        # aggregate
        global_model = aggregate_updates(global_model, committed_updates)

        m_selected = len(selected)
        m_committed = len(committed_updates)
        dropout_rate = 0.0 if m_selected == 0 else (m_selected - m_committed) / float(m_selected)

        srv = ServerRoundRow(
            run_id=run_id,
            round=r,
            m_selected=m_selected,
            m_committed=m_committed,
            dropout_rate=dropout_rate,
            global_model_norm=vec_norm(global_model),
            co2_committed_g=co2_committed,
            co2_dropped_g=co2_dropped,
            co2_total_g=co2_committed + co2_dropped,
        )
        server_rows.append(asdict(srv))

        # advance virtual time: end of round at deadline (sync FL)
        t_sim = t_deadline

        print(
            f"[round {r}] candidates={len(candidates)} selected={m_selected} "
            f"committed={m_committed} dropout={dropout_rate:.2f} "
            f"model_norm={srv.global_model_norm:.3f}"
        )

    # write logs
    clients_csv = os.path.join(run_dir, "clients_round.csv")
    server_csv = os.path.join(run_dir, "server_round.csv")

    # field order
    client_fields = list(asdict(ClientRoundRow(
        run_id="", round=0, veh_id="", selected=0, committed=0, drop_reason="",
        t_round_start=0, t_dl_done=0, t_ul_start=0, t_ul_done=0,
        t_down=0, t_train=0, t_up=0,
        dl_ok=0, ul_ok=0,
        dl_goodput_mbps=0, ul_goodput_mbps=0,
        dl_rtt_ms=0, ul_rtt_ms=0,
        e_comp_j=0, co2_comp_g=0,
        e_comm_j=0, co2_comm_g=0,
        co2_total_g=0
    )).keys())

    server_fields = list(asdict(ServerRoundRow(
        run_id="", round=0, m_selected=0, m_committed=0, dropout_rate=0.0,
        global_model_norm=0.0,
        co2_committed_g=0.0, co2_dropped_g=0.0, co2_total_g=0.0
    )).keys())

    write_csv(clients_csv, clients_rows, client_fields)
    write_csv(server_csv, server_rows, server_fields)

    print(f"[orchestrator] wrote: {clients_csv}")
    print(f"[orchestrator] wrote: {server_csv}")


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser()
    p.add_argument("--mode", choices=["mock", "rpc"], default="mock", help="Veins mode")
    p.add_argument("--host", default="127.0.0.1", help="Veins RPC host")
    p.add_argument("--port", type=int, default=9999, help="Veins RPC port")
    p.add_argument("--rounds", type=int, default=10, help="Number of FL rounds")
    p.add_argument("--m", type=int, default=10, help="Clients per round")
    p.add_argument("--deadline", type=float, default=25.0, help="Round deadline (virtual seconds)")
    p.add_argument("--out", default="outputs", help="Output root folder")
    return p.parse_args()


def main() -> None:
    args = parse_args()
    cfg = SimConfig()
    cfg.rounds = args.rounds
    cfg.clients_per_round = args.m
    cfg.round_deadline_s = args.deadline
    run(cfg=cfg, mode=args.mode, host=args.host, port=args.port, out_root=args.out)


if __name__ == "__main__":
    main()
```

---

## orchestrator/veins_client.py
<a id="orchestratorveinsclientpy"></a>

- Path: `/home/veins/fedits-tool/orchestrator/veins_client.py`
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Veins client abstraction.

- MockVeinsClient: runs immediately without any OMNeT++ changes.
- RPCVeinsClient: TCP/JSON-lines client to a future ControlServer inside Veins.

JSON-lines (one request per line) suggested contract:
Request:
  {"cmd":"get_state","t":12.3}
  {"cmd":"simulate_downlink","t_now":0.0,"veh_ids":["veh0"],"size_bytes":2000000,"deadline":25.0}
  {"cmd":"simulate_uplink","veh_ids":["veh0"],"size_bytes":2000000,"deadline":25.0,"start_times":{"veh0":4.2}}

Response:
  {"ok":true, ... payload ...}
"""

from __future__ import annotations

import json
import math
import random
import socket
from dataclasses import dataclass
from typing import Dict, List, Optional


# -----------------------------
# Data structures
# -----------------------------

@dataclass
class VehicleState:
    x_m: float
    y_m: float
    in_range: bool


@dataclass
class VeinsState:
    vehicles: Dict[str, VehicleState]


@dataclass
class DLResult:
    ok: bool
    t_done: float
    goodput_mbps: float
    rtt_ms: float
    reason: str = ""

    @staticmethod
    def fail(reason: str = "dl_failed") -> "DLResult":
        return DLResult(ok=False, t_done=-1.0, goodput_mbps=0.0, rtt_ms=0.0, reason=reason)


@dataclass
class ULResult:
    ok: bool
    t_done: float
    goodput_mbps: float
    rtt_ms: float
    reason: str = ""

    @staticmethod
    def fail(reason: str = "ul_failed") -> "ULResult":
        return ULResult(ok=False, t_done=-1.0, goodput_mbps=0.0, rtt_ms=0.0, reason=reason)


# -----------------------------
# Base Interface
# -----------------------------

class BaseVeinsClient:
    def get_state(self, t: float) -> VeinsState:
        raise NotImplementedError

    def simulate_downlink(self, t_now: float, veh_ids: List[str], size_bytes: int, deadline: float) -> Dict[str, DLResult]:
        raise NotImplementedError

    def simulate_uplink(self, start_times: Dict[str, float], veh_ids: List[str], size_bytes: int, deadline: float) -> Dict[str, ULResult]:
        raise NotImplementedError


# -----------------------------
# Mock Veins (immediate runnable)
# -----------------------------

class MockVeinsClient(BaseVeinsClient):
    """
    Very lightweight mobility + link model:
    - Vehicles move with constant velocity in a torus [0, map_size)
    - in_range determined by distance to RSU <= rsu_radius
    - goodput decreases with distance; if out_of_range => fail
    - transfer fails if it would finish after deadline or leaves range during transfer (rough check)
    """

    def __init__(
        self,
        map_size_m: float,
        num_vehicles: int,
        rsu_x_m: float,
        rsu_y_m: float,
        rsu_radius_m: float,
        seed: int = 42,
    ) -> None:
        self.map_size_m = float(map_size_m)
        self.rsu_x_m = float(rsu_x_m)
        self.rsu_y_m = float(rsu_y_m)
        self.rsu_radius_m = float(rsu_radius_m)

        rnd = random.Random(seed)
        self.veh_init = {}
        self.veh_vel = {}
        for i in range(num_vehicles):
            vid = f"veh{i}"
            x0 = rnd.uniform(0, self.map_size_m)
            y0 = rnd.uniform(0, self.map_size_m)
            # speed 5~20 m/s, random direction
            spd = rnd.uniform(5.0, 20.0)
            ang = rnd.uniform(0, 2.0 * math.pi)
            vx = spd * math.cos(ang)
            vy = spd * math.sin(ang)
            self.veh_init[vid] = (x0, y0)
            self.veh_vel[vid] = (vx, vy)

        self.rnd = random.Random(seed + 999)

    def _pos(self, vid: str, t: float) -> tuple[float, float]:
        x0, y0 = self.veh_init[vid]
        vx, vy = self.veh_vel[vid]
        x = (x0 + vx * t) % self.map_size_m
        y = (y0 + vy * t) % self.map_size_m
        return x, y

    def _dist(self, x: float, y: float) -> float:
        return math.hypot(x - self.rsu_x_m, y - self.rsu_y_m)

    def _in_range(self, x: float, y: float) -> bool:
        return self._dist(x, y) <= self.rsu_radius_m

    def _goodput_mbps(self, dist: float) -> float:
        """
        Simple distance-based goodput:
        near -> up to ~25 Mbps
        at edge -> ~2 Mbps
        """
        if dist <= 1.0:
            return 25.0
        if dist >= self.rsu_radius_m:
            return 0.0
        # smooth decay
        frac = dist / self.rsu_radius_m
        return max(2.0, 25.0 * (1.0 - frac) ** 1.2)

    def _rtt_ms(self, dist: float) -> float:
        # baseline + distance-based
        base = 5.0
        return base + 0.05 * dist + self.rnd.uniform(0.0, 2.0)

    def get_state(self, t: float) -> VeinsState:
        vehicles: Dict[str, VehicleState] = {}
        for vid in self.veh_init.keys():
            x, y = self._pos(vid, t)
            vehicles[vid] = VehicleState(x_m=x, y_m=y, in_range=self._in_range(x, y))
        return VeinsState(vehicles=vehicles)

    def simulate_downlink(self, t_now: float, veh_ids: List[str], size_bytes: int, deadline: float) -> Dict[str, DLResult]:
        res: Dict[str, DLResult] = {}
        for vid in veh_ids:
            x, y = self._pos(vid, t_now)
            dist = self._dist(x, y)
            if dist > self.rsu_radius_m:
                res[vid] = DLResult.fail("out_of_range")
                continue

            gp = self._goodput_mbps(dist)
            if gp <= 0.0:
                res[vid] = DLResult.fail("link_down")
                continue

            # transfer time (seconds)
            bytes_per_s = gp * 1_000_000 / 8.0
            t_tx = size_bytes / bytes_per_s
            # add small jitter
            t_tx *= self.rnd.uniform(1.0, 1.2)

            t_done = t_now + t_tx
            if t_done > deadline:
                res[vid] = DLResult.fail("dl_deadline_miss")
                continue

            # rough: if vehicle leaves range by t_done -> fail
            x2, y2 = self._pos(vid, t_done)
            if not self._in_range(x2, y2):
                res[vid] = DLResult.fail("dl_left_range")
                continue

            res[vid] = DLResult(ok=True, t_done=t_done, goodput_mbps=gp, rtt_ms=self._rtt_ms(dist))
        return res

    def simulate_uplink(self, start_times: Dict[str, float], veh_ids: List[str], size_bytes: int, deadline: float) -> Dict[str, ULResult]:
        res: Dict[str, ULResult] = {}
        for vid in veh_ids:
            t_start = start_times.get(vid, None)
            if t_start is None:
                res[vid] = ULResult.fail("no_start_time")
                continue
            if t_start > deadline:
                res[vid] = ULResult.fail("ul_start_after_deadline")
                continue

            x, y = self._pos(vid, t_start)
            dist = self._dist(x, y)
            if dist > self.rsu_radius_m:
                res[vid] = ULResult.fail("ul_out_of_range")
                continue

            gp = self._goodput_mbps(dist)
            if gp <= 0.0:
                res[vid] = ULResult.fail("ul_link_down")
                continue

            bytes_per_s = gp * 1_000_000 / 8.0
            t_tx = size_bytes / bytes_per_s
            # contention-like jitter (slightly larger uplink variance)
            t_tx *= self.rnd.uniform(1.05, 1.35)

            t_done = t_start + t_tx
            if t_done > deadline:
                res[vid] = ULResult.fail("ul_deadline_miss")
                continue

            x2, y2 = self._pos(vid, t_done)
            if not self._in_range(x2, y2):
                res[vid] = ULResult.fail("ul_left_range")
                continue

            res[vid] = ULResult(ok=True, t_done=t_done, goodput_mbps=gp, rtt_ms=self._rtt_ms(dist))
        return res


# -----------------------------
# RPC Veins Client (for real integration later)
# -----------------------------

class RPCVeinsClient(BaseVeinsClient):
    """
    TCP/JSON-lines client. You implement a corresponding ControlServer in Veins.
    """

    def __init__(self, host: str, port: int, timeout_s: float = 10.0) -> None:
        self.host = host
        self.port = int(port)
        self.timeout_s = float(timeout_s)

    def _call(self, payload: dict) -> dict:
        msg = (json.dumps(payload) + "\n").encode("utf-8")
        with socket.create_connection((self.host, self.port), timeout=self.timeout_s) as s:
            s.sendall(msg)
            s.shutdown(socket.SHUT_WR)
            data = b""
            while True:
                chunk = s.recv(4096)
                if not chunk:
                    break
                data += chunk
        text = data.decode("utf-8").strip()
        if not text:
            raise RuntimeError("Empty response from Veins ControlServer")
        return json.loads(text)

    def get_state(self, t: float) -> VeinsState:
        resp = self._call({"cmd": "get_state", "t": t})
        if not resp.get("ok", False):
            raise RuntimeError(f"Veins get_state failed: {resp}")
        vehicles = {}
        for vid, v in resp["vehicles"].items():
            vehicles[vid] = VehicleState(
                x_m=float(v["x_m"]),
                y_m=float(v["y_m"]),
                in_range=bool(v["in_range"]),
            )
        return VeinsState(vehicles=vehicles)

    def simulate_downlink(self, t_now: float, veh_ids: List[str], size_bytes: int, deadline: float) -> Dict[str, DLResult]:
        resp = self._call({
            "cmd": "simulate_downlink",
            "t_now": t_now,
            "veh_ids": veh_ids,
            "size_bytes": int(size_bytes),
            "deadline": float(deadline),
        })
        if not resp.get("ok", False):
            raise RuntimeError(f"Veins simulate_downlink failed: {resp}")
        out = {}
        for vid, r in resp["results"].items():
            out[vid] = DLResult(
                ok=bool(r["ok"]),
                t_done=float(r.get("t_done", -1.0)),
                goodput_mbps=float(r.get("goodput_mbps", 0.0)),
                rtt_ms=float(r.get("rtt_ms", 0.0)),
                reason=str(r.get("reason", "")),
            )
        return out

    def simulate_uplink(self, start_times: Dict[str, float], veh_ids: List[str], size_bytes: int, deadline: float) -> Dict[str, ULResult]:
        resp = self._call({
            "cmd": "simulate_uplink",
            "veh_ids": veh_ids,
            "start_times": start_times,
            "size_bytes": int(size_bytes),
            "deadline": float(deadline),
        })
        if not resp.get("ok", False):
            raise RuntimeError(f"Veins simulate_uplink failed: {resp}")
        out = {}
        for vid, r in resp["results"].items():
            out[vid] = ULResult(
                ok=bool(r["ok"]),
                t_done=float(r.get("t_done", -1.0)),
                goodput_mbps=float(r.get("goodput_mbps", 0.0)),
                rtt_ms=float(r.get("rtt_ms", 0.0)),
                reason=str(r.get("reason", "")),
            )
        return out
```

---

## README.md
<a id="readmemd"></a>

- Path: `/home/veins/fedits-tool/README.md`
````markdown
# FedITS-Tool (Veins + SUMO + FL Orchestrator skeleton)

This repository is a minimal, runnable scaffold for an *online* co-simulation tool:
- Mobility + wireless/network decisions come from **Veins/SUMO (sim time)**
- Local training runs in **Docker/Flower (real compute)**
- **Orchestrator** enforces commit/drop semantics and logs per-round latency/energy/carbon

## Quick start (runs immediately, no Veins/Flower required)

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Run mock end-to-end (produces outputs/runs/<run_id>/csv)
make run-mock
````

---

## requirements.txt
<a id="requirementstxt"></a>

- Path: `/home/veins/fedits-tool/requirements.txt`
```
numpy>=1.23
pyyaml>=6.0
flwr>=1.6.0
```

---

## scripts/collect_last_run.sh
<a id="scriptscollectlastrunsh"></a>

- Path: `/home/veins/fedits-tool/scripts/collect_last_run.sh`
```bash
#!/usr/bin/env bash
set -euo pipefail

LAST_DIR=$(ls -1dt outputs/runs/* 2>/dev/null | head -n 1 || true)
if [ -z "${LAST_DIR}" ]; then
  echo "No runs found under outputs/runs/"
  exit 1
fi

echo "Last run: ${LAST_DIR}"
echo "Files:"
ls -lh "${LAST_DIR}"
```

---

## scripts/run_mock.sh
<a id="scriptsrunmocksh"></a>

- Path: `/home/veins/fedits-tool/scripts/run_mock.sh`
```bash
#!/usr/bin/env bash
set -euo pipefail

ROUNDS="${ROUNDS:-5}"
M="${M:-10}"
DEADLINE="${DEADLINE:-25}"

source .venv/bin/activate
python orchestrator/orchestrator.py --mode mock --rounds "${ROUNDS}" --m "${M}" --deadline "${DEADLINE}"
```

---

## scripts/run_rpc.sh
<a id="scriptsrunrpcsh"></a>

- Path: `/home/veins/fedits-tool/scripts/run_rpc.sh`
```bash
#!/usr/bin/env bash
set -euo pipefail

HOST="${HOST:-127.0.0.1}"
PORT="${PORT:-9999}"
ROUNDS="${ROUNDS:-5}"
M="${M:-10}"
DEADLINE="${DEADLINE:-25}"

source .venv/bin/activate
python orchestrator/orchestrator.py --mode rpc --host "${HOST}" --port "${PORT}" --rounds "${ROUNDS}" --m "${M}" --deadline "${DEADLINE}"
```

---

